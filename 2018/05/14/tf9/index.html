<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">






  
  
  <link rel="stylesheet" media="all" href="/lib/Han/dist/han.min.css?v=3.3">




<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="tensorflow," />





  <link rel="alternate" href="/atom.xml" title="离弦的博客" type="application/atom+xml" />






<meta name="description" content="1、MNIST数据集介绍&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;首先介绍MNIST数据集。如果所示，MNIST数据集主要由一些手写数字的图片和相应的标签组成，图片一共有10类，分别对应0~9，共10个阿拉伯数字。如下图：  MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取, 它包含了四个部分:">
<meta name="keywords" content="tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="tensorflow入门笔记1">
<meta property="og:url" content="https://goingcoder.github.io/2018/05/14/tf9/index.html">
<meta property="og:site_name" content="离弦的博客">
<meta property="og:description" content="1、MNIST数据集介绍&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;首先介绍MNIST数据集。如果所示，MNIST数据集主要由一些手写数字的图片和相应的标签组成，图片一共有10类，分别对应0~9，共10个阿拉伯数字。如下图：  MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取, 它包含了四个部分:">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://goingcoder.github.io/2018/05/14/tf9/image1.png">
<meta property="og:updated_time" content="2018-05-14T11:57:59.382Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="tensorflow入门笔记1">
<meta name="twitter:description" content="1、MNIST数据集介绍&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;首先介绍MNIST数据集。如果所示，MNIST数据集主要由一些手写数字的图片和相应的标签组成，图片一共有10类，分别对应0~9，共10个阿拉伯数字。如下图：  MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取, 它包含了四个部分:">
<meta name="twitter:image" content="https://goingcoder.github.io/2018/05/14/tf9/image1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.3',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://goingcoder.github.io/2018/05/14/tf9/"/>





  <title>tensorflow入门笔记1 | 离弦的博客</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?your-analytics-id";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband">
		
	</div>
	
	
	
	<a href="https://github.com/goingcoder" class="github-corner" aria-label="View source on Github">
		<svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true">
			<path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    
	
	<header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">离弦的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">我若为王,舍我其谁</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'your-swiftype-key','2.0.0');
</script>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://goingcoder.github.io/2018/05/14/tf9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="goingcoder">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/23649220?s=400&u=964c794854ddfd2a46f55952deb5f1010bbd2982&v=4">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="离弦的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">tensorflow入门笔记1</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-14T15:29:59+08:00">
                2018-05-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tensorflow/" itemprop="url" rel="index">
                    <span itemprop="name">tensorflow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/05/14/tf9/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/05/14/tf9/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h2 id="1、MNIST数据集介绍"><a href="#1、MNIST数据集介绍" class="headerlink" title="1、MNIST数据集介绍"></a>1、MNIST数据集介绍</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先介绍MNIST数据集。如果所示，MNIST数据集主要由一些手写数字的图片和相应的标签组成，图片一共有10类，分别对应0~9，共10个阿拉伯数字。如下图：</p>
<p><img src="/2018/05/14/tf9/image1.png" alt="1"></p>
<p>MNIST 数据集可在 <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a> 获取, 它包含了四个部分:</p>
<ul>
<li><strong>Training set images</strong>: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本)</li>
<li><strong>Training set labels</strong>: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签)</li>
<li><strong>Test set images</strong>: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本)</li>
<li><strong>Test set labels</strong>: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签)</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MNIST 数据集来自美国国家标准与技术研究所, <strong>National Institute of Standards and Technology (NIST)</strong>. 训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员. 测试集(test set) 也是同样比例的手写数字数据。 60,000 个训练样本和 10,000 个测试样本. </p>
<a id="more"></a>
<h2 id="2、下载数据集"><a href="#2、下载数据集" class="headerlink" title="2、下载数据集"></a>2、下载数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从tensorflow.examples.tutorials.mnist引入模块。这是TensorFlow为了教学MNIST而提前编制的程序</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="comment"># 从MNIST_data/中读取MNIST数据。这条语句在数据不存在时，会自动执行下载</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在执行语句mnist = input_data.read_data_sets(“MNIST_data/“, one_hot=True)时，Tensorflow会检测数据是否存在。当数据不存在时，系统自动将数据下载到MNIST_data/文件夹中。当执行完语句后，可以看到MNIST_data/文件夹下多了4个上述文件。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;成功加载数据后，得到了一个mnist对象，可以通过mnist对象的数学访问到MNIST数据集。</p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>内容</th>
<th>大小</th>
</tr>
</thead>
<tbody>
<tr>
<td>mnist.train,images</td>
<td>训练图像</td>
<td>(55000,784)</td>
</tr>
<tr>
<td>mnist.train.label</td>
<td>训练标签</td>
<td>(55000,10)</td>
</tr>
<tr>
<td>mnist.validation.images</td>
<td>验证图像</td>
<td>（5000,784）</td>
</tr>
<tr>
<td>mnist.validation.labels</td>
<td>验证标签</td>
<td>（5000,10）</td>
</tr>
<tr>
<td>mnist.test.images</td>
<td>测试图像</td>
<td>（10000,784）</td>
</tr>
<tr>
<td>mnist.test.labels</td>
<td>测试标签</td>
<td>（10000,10）</td>
</tr>
</tbody>
</table>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;运行下面代码可以查看各个变量的形状大小：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看训练数据的大小</span></span><br><span class="line">print(mnist.train.images.shape)  <span class="comment"># (55000, 784)</span></span><br><span class="line">print(mnist.train.labels.shape)  <span class="comment"># (55000, 10)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看验证数据的大小</span></span><br><span class="line">print(mnist.validation.images.shape)  <span class="comment"># (5000, 784)</span></span><br><span class="line">print(mnist.validation.labels.shape)  <span class="comment"># (5000, 10)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看测试数据的大小</span></span><br><span class="line">print(mnist.test.images.shape)  <span class="comment"># (10000, 784)</span></span><br><span class="line">print(mnist.test.labels.shape)  <span class="comment"># (10000, 10)</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 原始的MNIST数据集中包含了60000张训练图片和10000张测试图片。而在tensorflow中，又将原先的60000张训练图片重新划分成了新的55000张训练图片和5000张验证图片。所以在mnist对象中，数据一共分为三部分：mnist.train是训练图片数据，mnist.validation是验证图片数据，mnist.test是测试图片数据，这正好对应了机器学习中额训练集、验证集和测试集、一般来说，会在训练集上训练模型，通过在验证集上调整参数，最后通过测试集确定模型的性能。</p>
<p>MNIST数据集保存为图片</p>
<p>为了加深理解，将MNIST数据集读取出来，并保存为图片文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取MNIST数据集。如果不存在会事先下载。</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 我们把原始图片保存在MNIST_data/raw/文件夹下</span></span><br><span class="line"><span class="comment"># 如果没有这个文件夹会自动创建</span></span><br><span class="line">save_dir = <span class="string">'MNIST_data/raw/'</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(save_dir) <span class="keyword">is</span> <span class="keyword">False</span>:</span><br><span class="line">    os.makedirs(save_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存前20张图片</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    <span class="comment"># 请注意，mnist.train.images[i, :]就表示第i张图片（序号从0开始）</span></span><br><span class="line">    image_array = mnist.train.images[i, :]</span><br><span class="line">    <span class="comment"># TensorFlow中的MNIST图片是一个784维的向量，我们重新把它还原为28x28维的图像。</span></span><br><span class="line">    image_array = image_array.reshape(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    <span class="comment"># 保存文件的格式为 mnist_train_0.jpg, mnist_train_1.jpg, ... ,mnist_train_19.jpg</span></span><br><span class="line">    filename = save_dir + <span class="string">'mnist_train_%d.jpg'</span> % i</span><br><span class="line">    <span class="comment"># 将image_array保存为图片</span></span><br><span class="line">    <span class="comment"># 先用scipy.misc.toimage转换为图像，再调用save直接保存。</span></span><br><span class="line">    scipy.misc.toimage(image_array, cmin=<span class="number">0.0</span>, cmax=<span class="number">1.0</span>).save(filename)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Please check: %s '</span> % save_dir)</span><br></pre></td></tr></table></figure>
<h2 id="3、图像标签的独热表示"><a href="#3、图像标签的独热表示" class="headerlink" title="3、图像标签的独热表示"></a>3、图像标签的独热表示</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;变量mnist.train.labels表示训练数据的标签，它的形状是(55000,10)。原始的图像标签是数字0-9，我们完全可以用一个数字来存储图像标签，但为什么这里每个训练标签是一个10维的向量呢？其实，这个10维的向量是原先类别的独热(one-hot)表示。</p>
<h2 id="4、Softmax回归识别MNIST"><a href="#4、Softmax回归识别MNIST" class="headerlink" title="4、Softmax回归识别MNIST"></a>4、Softmax回归识别MNIST</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;softmax回归是一个线性的多分类模型，实际上它是从Logistic回归模型转化而来的。区别是Logistic回归模型是一个两分类模型，而Softmax模型为多分类模型。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在手写体识别问题中，一共有10个类别(0~9)，我们希望对输入的图像计算它属于每个类别的概率。如属于9的概率为70%，属于1的概率为10%等。最后模型预测的结果就是概率最大的那个类别。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先来了解什么是Softmax函数。Softmax函数的主要功能是将各个类别的“打分“转化成合理的概率值。例如，一个样本可能属于三个类别：第一个类别的打分为a，第二个类别的打分为b，第三个类别的打分为c。打分越高代表属于这个类别的概率越高，但是打分本身不代表概率，因为打分的值可以使负数，也可以很大。但概率要求值必须在0~1，并且三类的概率加起来等于1.那么，如何将(a,b,c)转换成合理的概率值呢？方法就是使用Softmax函数。例如，对(a,b,c)使用softmax函数后，相异的值会变成$({e^a \over e^a+e^b+e^c},{e^b \over e^a+e^b+e^c},{e^c \over e^a+e^b+e^c})$，也就是说，第一类的概率用$e^a \over e^a+e^b+e^c$来表示，第二类用$e^b \over e^a+e^b+e^c$来表示，第三类可以用$e^c \over e^a+e^b+e^c$来表示。显然，这三个数都在0~1之间，并且加起来正好等于1，是合理的概率表示。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设$x$是单个样本的特征，$W,b$是Softmax模型的参数。在MNIST数据集中，$x$就代表输入图片，它是一个784维的向量，而$W$是一个矩阵，它的形状为(784,10),$b$是一个10维的向量，10代表的是类别数。Softmax模型的第一步是通过下面的公司计算各个类别的Logit：<br>$$<br>Logit=W^Tx+b<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Logit同样是一个10维的向量，它的实际上可以看出样本对于于各个类别的“打分”。接下来使用Softmax函数将他转换成各个类别的概率值：<br>$$<br>y=Softmax(Logit)<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Softmax模型输出的y代表各个类别的概率，还可以直接用下面的式子来表示整个Softmax模型：<br>$$<br>y=Softmax(W^Tx+b)<br>$$</p>
<p>##5、Softmax实现</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先导入tensorflow模型,下面是约定俗成的写法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接下来导入MNIST数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;构建模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建x，x是一个占位符（placeholder），代表待识别的图片</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line"><span class="comment"># W是Softmax模型的参数，将一个784维的输入转换为一个10维的输出</span></span><br><span class="line"><span class="comment"># 在TensorFlow中，变量的参数用tf.Variable表示</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line"><span class="comment"># b是又一个Softmax模型的参数，我们一般叫做“偏置项”（bias）。</span></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># y=softmax(Wx + b)，y表示模型的输出</span></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)</span><br><span class="line"><span class="comment"># y_是实际的图像标签，同样以占位符表示。</span></span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里定义了一下占位符(placeholder)和变量(Variable).在tensorflow中无论是占位符还是变量，它们实际上都是“Tensor”。从Tensorflow的名字中就可以看出Tensor在整个系统处于核心地位。Tensor并不是具体的数值，它只是一些我们”希望“Tensorflow系统计算的“节点”。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里的占位符和变量是不同类型的Tensor。先来讲解占位符。占位符不依赖于其它的Tensor，它的值由用户自行传到给Tensorflow，通常用来存储样本数据和标签。如在这里定义了x = tf.placeholder(tf.float32, [None, 784])，它是用来存储训练图片数据的占位符，它的形状为[None, 784]，None表示这一维的大小是任意的，也就是说可以传递任意章训练图片给这个占位符，每张图片用784维的向量表示。同样的，y_ = tf.placeholder(tf.float32, [None, 10])也是一个占位符，它存储训练图片的实际标签。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再来看什么是变量，变量是指在计算过程中可以改变的值，每次计算后变量的值会被保存下来，通常用变量来存储模型的参数。如：W = tf.Variable(tf.zeros([784, 10]))。创建变量时通常要指定某些初始值。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了变量和占位符之外，还创建了一个y</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个y就是一个依赖x，W，b的Tensor。如果要求Tensorflow计算y的值，那么系统首先会获取$x,W,b$的值，再去计算y的值</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y实际上定义了一个Softmax回归模型，在此可以尝试写出y的形状。假设输入x的形状为(N,784)，其中N表示输入的训练图像的数目。W的形状为（784,10），b的形状为（10），那么Wx+b的形状是(N,10)。Softmax函数不改变结果的形状，所以得到y的形状为(N,10)。也就是说，y的每一行是10维的向量，表示模型预测的样本对应到各个类别的概率。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;模型的输出是y，而实际的标签为y_,它们应当越相似越好。在Softmax回归模型中，通常使用“交叉熵”损失来衡量相似性。损失越小，模型的输出就和实际标签越接近，模型的预测也就越准确。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Tensorflow中，这样定义交叉熵损失：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据y, y_构造交叉熵损失</span></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y)))</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;构造玩损失之后，下面一步是如何优化损失，让损失减小。这里使用梯度下降优化损失，定义为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有了损失，我们就可以用随机梯度下降针对模型的参数（W和b）进行优化</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>
<p>​    Tensorfloe默认会对所有变量计算梯度。这里只定义两个变量$W$和$b$，因此程序将会使用梯度下降法对$W,b$计算梯度并更新它们的值。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在优化之前，必须要创建一个会话(Session),并在会话中对变量进行初始化操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个Session。只有在Session中才能运行优化步骤train_step。</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line"><span class="comment"># 运行之前必须要初始化所有变量，分配内存。</span></span><br><span class="line">tf.global_variables_initializer().run()</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有了会话，就可以对变量进行优化了，优化的程序如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># 在mnist.train中取100个训练数据</span></span><br><span class="line">    <span class="comment"># batch_xs是形状为(100, 784)的图像数据，batch_ys是形如(100, 10)的实际标签</span></span><br><span class="line">    <span class="comment"># batch_xs, batch_ys对应着两个占位符x和y_</span></span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    <span class="comment"># 在Session中运行train_step，运行时要传入占位符的值</span></span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与变量不同的是，占位符的值不会被保存，每次可以给占位符传递不同的值。</p>
<p>​    训练完成后，可以检测模型训练的结果，对于的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正确的预测结果</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 计算预测准确率，它们都是Tensor</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"><span class="comment"># 在Session中运行Tensor可以得到Tensor的值</span></span><br><span class="line"><span class="comment"># 这里是获取最终模型的正确率</span></span><br><span class="line">print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))  <span class="comment"># 0.9052</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;模型预测y的形状是(N,10)，而实际标签y_的形状是(N,10)，其中N为输入模型1的样本数。tf.argmax(y,1)、tf.argmax(y_,1)的功能是取出数组最大值得下标，可以用来将独热表示以及模型输出转换为数字标签。假设传入四个样本，它们的独热表示y_为（需要通过sess.run(y_)才能获取此Tensor的值，下同）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line"> [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]]</span><br></pre></td></tr></table></figure>
<p>tf.argmax(y_,1)就是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span>,<span class="number">2</span>,<span class="number">9</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>​    也就是说，取出每一行最大值对应的下标位置，它们是输入样本的实际标签。假设此时模型的预测输出y为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.91</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>],</span><br><span class="line"> [<span class="number">0.91</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>],</span><br><span class="line"> [<span class="number">0.91</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>],</span><br><span class="line"> [<span class="number">0.91</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>,<span class="number">0.01</span>]]</span><br></pre></td></tr></table></figure>
<p>tf.argmax(y_,1)就是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>​    得到预测的标签和实际标签，接下来通过tf.equal函数来比较它们是否相等，并将结果保存到correct_prediction中。在上述例子中，correct_prediction就是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">True</span>,<span class="keyword">False</span>,<span class="keyword">True</span>,<span class="keyword">False</span>]</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;即第一个样本和最后一个样本预测是正确的，另外两个样本预测错误。可以用tf.cast(correct_prediction,tf.float32)将比较值转换成float32型的变量，此时True会被转换成1，False会被转换为0.在上述例子中，tf.cast(correct_prediction, tf.float32)的结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1.</span>,<span class="number">0.</span>,<span class="number">0.</span>,<span class="number">1.</span>]</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，用tf.reduce_mean可以计算数组中的所有元素的平均值，相当于得到了模型的预测准确率，如[1.,0.,0.,1.]的平均值为0,5，即50%的分类准确率。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在程序softmax_regression.py中，传入占位符的值是feed_dict={x: mnist.test.images, y_: mnist.test.labels}。也就是说，使用全体测试样本进行测试，测试图片一共10000张，运行的结果为0.9052，即90.52%的准确率。因为softmax回归是一个比较简单的模型，这里的预测准确率并不高。</p>
<p>完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 导入MNIST教学的模块</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建x，x是一个占位符（placeholder），代表待识别的图片</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line"><span class="comment"># W是Softmax模型的参数，将一个784维的输入转换为一个10维的输出</span></span><br><span class="line"><span class="comment"># 在TensorFlow中，变量的参数用tf.Variable表示</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line"><span class="comment"># b是又一个Softmax模型的参数，我们一般叫做“偏置项”（bias）。</span></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># y=softmax(Wx + b)，y表示模型的输出</span></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)</span><br><span class="line"><span class="comment"># y_是实际的图像标签，同样以占位符表示。</span></span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 至此，我们得到了两个重要的Tensor：y和y_。</span></span><br><span class="line"><span class="comment"># y是模型的输出，y_是实际的图像标签，不要忘了y_是独热表示的</span></span><br><span class="line"><span class="comment"># 下面我们就会根据y和y_构造损失</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据y, y_构造交叉熵损失</span></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y)))</span><br><span class="line"><span class="comment"># 有了损失，我们就可以用随机梯度下降针对模型的参数（W和b）进行优化</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Session。只有在Session中才能运行优化步骤train_step。</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line"><span class="comment"># 运行之前必须要初始化所有变量，分配内存。</span></span><br><span class="line">tf.global_variables_initializer().run()</span><br><span class="line">print(<span class="string">'start training...'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行1000步梯度下降</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># 在mnist.train中取100个训练数据</span></span><br><span class="line">    <span class="comment"># batch_xs是形状为(100, 784)的图像数据，batch_ys是形如(100, 10)的实际标签</span></span><br><span class="line">    <span class="comment"># batch_xs, batch_ys对应着两个占位符x和y_</span></span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    <span class="comment"># 在Session中运行train_step，运行时要传入占位符的值</span></span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正确的预测结果</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 计算预测准确率，它们都是Tensor</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"><span class="comment"># 在Session中运行Tensor可以得到Tensor的值</span></span><br><span class="line"><span class="comment"># 这里是获取最终模型的正确率</span></span><br><span class="line">print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<p><div id="container"></div></p>
<p><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"></p>
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
var gitment = new Gitment({
  id:  'window.location.pathname', // 可选。默认为 location.href
  title:  'tensorflow入门笔记1',
  owner: 'goingcoder',
  repo: 'goingcoder.github.io',
  oauth: {

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">client_id: &apos;de24b44123b8efbb4747&apos;,</span><br><span class="line">client_secret: &apos;785f51974278cde45a927a91a8438ef35eab9dd0&apos;,</span><br></pre></td></tr></table></figure>

  },
})
gitment.render('container')
</script>






      
    </div>
    
    
    

    

	<div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/2018/05/14/tf9/">tensorflow入门笔记1</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 goingcoder 的个人博客">goingcoder</a></p>
  <p><span>发布时间:</span>2018年05月14日 - 15:05</p>
  <p><span>最后更新:</span>2018年05月14日 - 19:05</p>
  <p><span>原始链接:</span><a href="/2018/05/14/tf9/" title="tensorflow入门笔记1">https://goingcoder.github.io/2018/05/14/tf9/</a>
    <span class="copy-path"  title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://goingcoder.github.io/2018/05/14/tf9/"  aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
      $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
        });
    });  
</script>

      
	</div>
	
	
	<div>
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
	</div>
	
	
	
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/11/embedding/" rel="next" title="embedding">
                <i class="fa fa-chevron-left"></i> embedding
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/17/tf10/" rel="prev" title="CNN卷积神经网络对MNIST数据分类">
                CNN卷积神经网络对MNIST数据分类 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div class="ds-thread" data-thread-key="2018/05/14/tf9/"
           data-title="tensorflow入门笔记1" data-url="https://goingcoder.github.io/2018/05/14/tf9/">
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://avatars1.githubusercontent.com/u/23649220?s=400&u=964c794854ddfd2a46f55952deb5f1010bbd2982&v=4"
                alt="goingcoder" />
            
              <p class="site-author-name" itemprop="name">goingcoder</p>
              <p class="site-description motion-element" itemprop="description">匆忙世间的闲人。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/goingcoder" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            
          </div>

          
          
            <div class="cc-license motion-element" itemprop="license">
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
                <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
              </a>
            </div>
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.hustyrf.top" title="陈冠希" target="_blank">陈冠希</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1、MNIST数据集介绍"><span class="nav-number">1.</span> <span class="nav-text"><a href="#1&#x3001;MNIST&#x6570;&#x636E;&#x96C6;&#x4ECB;&#x7ECD;" class="headerlink" title="1&#x3001;MNIST&#x6570;&#x636E;&#x96C6;&#x4ECB;&#x7ECD;"></a>1&#x3001;MNIST&#x6570;&#x636E;&#x96C6;&#x4ECB;&#x7ECD;</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2、下载数据集"><span class="nav-number">2.</span> <span class="nav-text"><a href="#2&#x3001;&#x4E0B;&#x8F7D;&#x6570;&#x636E;&#x96C6;" class="headerlink" title="2&#x3001;&#x4E0B;&#x8F7D;&#x6570;&#x636E;&#x96C6;"></a>2&#x3001;&#x4E0B;&#x8F7D;&#x6570;&#x636E;&#x96C6;</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3、图像标签的独热表示"><span class="nav-number">3.</span> <span class="nav-text"><a href="#3&#x3001;&#x56FE;&#x50CF;&#x6807;&#x7B7E;&#x7684;&#x72EC;&#x70ED;&#x8868;&#x793A;" class="headerlink" title="3&#x3001;&#x56FE;&#x50CF;&#x6807;&#x7B7E;&#x7684;&#x72EC;&#x70ED;&#x8868;&#x793A;"></a>3&#x3001;&#x56FE;&#x50CF;&#x6807;&#x7B7E;&#x7684;&#x72EC;&#x70ED;&#x8868;&#x793A;</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4、Softmax回归识别MNIST"><span class="nav-number">4.</span> <span class="nav-text"><a href="#4&#x3001;Softmax&#x56DE;&#x5F52;&#x8BC6;&#x522B;MNIST" class="headerlink" title="4&#x3001;Softmax&#x56DE;&#x5F52;&#x8BC6;&#x522B;MNIST"></a>4&#x3001;Softmax&#x56DE;&#x5F52;&#x8BC6;&#x522B;MNIST</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">goingcoder</span>

  
</div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.3</div>

-->



        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"your-duoshuo-shortname"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  


















  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
