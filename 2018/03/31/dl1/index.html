<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">






  
  
  <link rel="stylesheet" media="all" href="/lib/Han/dist/han.min.css?v=3.3">




<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="离弦的博客" type="application/atom+xml" />






<meta name="description" content="线性单元​    感知器有一个问题，当面对的数据集不是线性可分的时候，『感知器规则』可能无法收敛，这意味着我们永远也无法完成一个感知器的训练。为了解决这个问题，我们使用一个可导的线性函数来替代感知器的阶跃函数，这种感知器就叫做线性单元。线性单元在面对线性不可分的数据集时，会收敛到一个最佳的近似上。 为了简单起见，我们可以设置线性单元的激活函数$f$为 $f(x)=x$ 这样的线性单元如下图所示">
<meta name="keywords" content="Hexo,next">
<meta property="og:type" content="article">
<meta property="og:title" content="dl1">
<meta property="og:url" content="https://goingcoder.github.io/2018/03/31/dl1/index.html">
<meta property="og:site_name" content="离弦的博客">
<meta property="og:description" content="线性单元​    感知器有一个问题，当面对的数据集不是线性可分的时候，『感知器规则』可能无法收敛，这意味着我们永远也无法完成一个感知器的训练。为了解决这个问题，我们使用一个可导的线性函数来替代感知器的阶跃函数，这种感知器就叫做线性单元。线性单元在面对线性不可分的数据集时，会收敛到一个最佳的近似上。 为了简单起见，我们可以设置线性单元的激活函数$f$为 $f(x)=x$ 这样的线性单元如下图所示">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://goingcoder.github.io/2018/03/31/dl1/image1.png">
<meta property="og:image" content="https://goingcoder.github.io/2018/03/31/dl1/image2.png">
<meta property="og:image" content="https://goingcoder.github.io/2018/03/31/dl1/image3.png">
<meta property="og:image" content="https://goingcoder.github.io/2018/03/31/dl1/image4.png">
<meta property="og:updated_time" content="2018-03-31T14:28:58.270Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="dl1">
<meta name="twitter:description" content="线性单元​    感知器有一个问题，当面对的数据集不是线性可分的时候，『感知器规则』可能无法收敛，这意味着我们永远也无法完成一个感知器的训练。为了解决这个问题，我们使用一个可导的线性函数来替代感知器的阶跃函数，这种感知器就叫做线性单元。线性单元在面对线性不可分的数据集时，会收敛到一个最佳的近似上。 为了简单起见，我们可以设置线性单元的激活函数$f$为 $f(x)=x$ 这样的线性单元如下图所示">
<meta name="twitter:image" content="https://goingcoder.github.io/2018/03/31/dl1/image1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.3',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://goingcoder.github.io/2018/03/31/dl1/"/>





  <title>dl1 | 离弦的博客</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?your-analytics-id";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband">
		
	</div>
	
	
	
	<a href="https://github.com/goingcoder" class="github-corner" aria-label="View source on Github">
		<svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true">
			<path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    
	
	<header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">离弦的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">我若为王,舍我其谁</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'your-swiftype-key','2.0.0');
</script>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://goingcoder.github.io/2018/03/31/dl1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="goingcoder">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/23649220?s=400&u=964c794854ddfd2a46f55952deb5f1010bbd2982&v=4">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="离弦的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">dl1</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-31T12:59:39+08:00">
                2018-03-31
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/31/dl1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/31/dl1/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h2 id="线性单元"><a href="#线性单元" class="headerlink" title="线性单元"></a>线性单元</h2><p>​    感知器有一个问题，当面对的数据集不是<strong>线性可分</strong>的时候，『感知器规则』可能无法收敛，这意味着我们永远也无法完成一个感知器的训练。为了解决这个问题，我们使用一个<strong>可导</strong>的<strong>线性函数</strong>来替代感知器的<strong>阶跃函数</strong>，这种感知器就叫做<strong>线性单元</strong>。线性单元在面对线性不可分的数据集时，会收敛到一个最佳的近似上。</p>
<p>为了简单起见，我们可以设置线性单元的激活函数$f$为</p>
<p>$f(x)=x$</p>
<p>这样的线性单元如下图所示    </p>
<p><img src="/2018/03/31/dl1/image1.png" alt="t1"></p>
<p>感知器</p>
<p><img src="/2018/03/31/dl1/image2.png" alt="t"></p>
<p>​    替换激活函数之后，<strong>线性单元</strong>将返回一个<strong>实数值</strong>而不是<strong>0,1分类</strong>。因此线性单元用来解决<strong>回归</strong>问题而不是<strong>分类</strong>问题。</p>
<h3 id="线性单元的模型"><a href="#线性单元的模型" class="headerlink" title="线性单元的模型"></a>线性单元的模型</h3><p>​    当我们说<strong>模型</strong>时，我们实际上在谈论根据输入$x$预测输出$y$的<strong>算法</strong>。比如，$x$可以是一个人的工作年限，$y$可以是他的月薪，我们可以用某种算法来根据一个人的工作年限来预测他的收入。比如：</p>
<p>$y=h(x)=w*x+b$</p>
<p>​    函数$h(x)$叫做<strong>假设</strong>，而$w,b$是它的<strong>参数</strong>。我们假设参数$w=1000$，参数$b=500$，如果一个人的工作年限是5年的话，我们的模型会预测他的月薪为</p>
<p>$y=h(x)=1000*5+500=5500（元）$</p>
<p>​    你也许会说，这个模型太不靠谱了。是这样的，因为我们考虑的因素太少了，仅仅包含了工作年限。如果考虑更多的因素，比如所处的行业、公司、职级等等，可能预测就会靠谱的多。我们把工作年限、行业、公司、职级这些信息，称之为<strong>特征</strong>。对于一个工作了5年，在IT行业，百度工作，职级T6这样的人，我们可以用这样的一个特征向量来表示他</p>
<p>$x=(5,IT,百度，T6)$</p>
<p>​    既然输入$x$变成了一个具备四个特征的向量，相对应的，仅仅一个参数$w$就不够用了，我们应该使用4个参数$w_1,w_2,w_3,w_4$，每个特征对应一个。这样，我们的模型就变成</p>
<p>$y=h(x)=w_1<em>x_1+w_2</em>x_2+w_3<em>x_3+w_4</em>x_4+b$</p>
<p>​    其中，$x_1$对应工作年限，$x_2$对应行业，$x_3$对应公司，$x_4$对应职称。</p>
<p>​    为了书写和计算方便，我们可以$w_0$令等于$b$，同时令$w_0$对应于特征$x_0$。由于$x_0$其实并不存在，我们可以令它的值永远为1。也就是说</p>
<p>$b=w_0*x_0$ 其中$x_0=1$</p>
<p>​    这样上面的式子就可以写成</p>
<p>$y=h(x)=w_1<em>x_1+w_2</em>x_2+w_3<em>x_3+w_4</em>x_4+b$              ………….(1)</p>
<p>$=w_0<em>x_0+w_1</em>x_1+w_2<em>x_2+w_3</em>x_3+w_4*x_4$                    ………….(2)</p>
<p>​    我们还可以把上式写成向量的形式</p>
<p>​    $y=h(x)=w^Tx$</p>
<p>​    长成这种样子模型就叫做<strong>线性模型</strong>，因为输出$y$就是输入特征$x_1,x_2,x_3,…$的<strong>线性组合</strong>。</p>
<h3 id="监督学习和无监督学习"><a href="#监督学习和无监督学习" class="headerlink" title="监督学习和无监督学习"></a>监督学习和无监督学习</h3><p>​    接下来，我们需要关心的是这个模型如何训练，也就是参数$w$取什么值最合适。</p>
<p>​    机器学习有一类学习方法叫做<strong>监督学习</strong>，它是说为了训练一个模型，我们要提供这样一堆训练样本：每个训练样本既包括输入特征$x$，也包括对应的输出$y$(也叫做<strong>标记，label</strong>)。也就是说，我们要找到很多人，我们既知道他们的特征(工作年限，行业…)，也知道他们的收入。我们用这样的样本去训练模型，让模型既看到我们提出的每个问题(输入特征)，也看到对应问题的答案(标记)。当模型看到足够多的样本之后，它就能总结出其中的一些规律。然后，就可以预测那些它没看过的输入所对应的答案了。</p>
<p>​    另外一类学习方法叫做<strong>无监督学习</strong>，这种方法的训练样本中只有而没有。模型可以总结出特征的一些规律，但是无法知道其对应的答案$y$。</p>
<p>​    很多时候，既有$x$又有的$y$训练样本是很少的，大部分样本都只有$x$。比如在语音到文本(STT)的识别任务中，$x$是语音，$y$是这段语音对应的文本。我们很容易获取大量的语音录音，然而把语音一段一段切分好并<strong>标注</strong>上对应文字则是非常费力气的事情。这种情况下，为了弥补带标注样本的不足，我们可以用<strong>无监督学习方法</strong>先做一些<strong>聚类</strong>，让模型总结出哪些音节是相似的，然后再用少量的带标注的训练样本，告诉模型其中一些音节对应的文字。这样模型就可以把相似的音节都对应到相应文字上，完成模型的训练。</p>
<h3 id="线性单元的目标函数"><a href="#线性单元的目标函数" class="headerlink" title="线性单元的目标函数"></a>线性单元的目标函数</h3><p>​    现在，让我们只考虑<strong>监督学习</strong>。</p>
<p>​    在监督学习下，对于一个样本，我们知道它的特征$x$，以及标记$y$。同时，我们还可以根据模型计算得到输出。注意这里面我们用表示训练样本里面的<strong>标记</strong>，也就是<strong>实际值</strong>；用带上划线的表示模型计算的出来的<strong>预测值</strong>。我们当然希望模型计算出来的和越接近越好。</p>
<p>​    数学上有很多方法来表示的$\overline y$和$y$的接近程度，比如我们可以用$\overline y$和$y$的差的平方的$1\over2$来表示它们的接近程度</p>
<p>$e={1\over2}(y-\overline y)^2$</p>
<p>​    我们把$e$叫做<strong>单个样本</strong>的<strong>误差</strong>。至于为什么前面要乘$1\over 2$，是为了后面计算方便。</p>
<p>训练数据中会有很多样本，比如$N$个，我们可以用训练数据中<strong>所有样本</strong>的误差的<strong>和</strong>，来表示模型的误差$E$，也就是$E=e^{(1)}+e^{(2)}+e^{(3)}+\dots+e^{(n)}$</p>
<p>​    上式的$e^{(1)}$表示第一个样本的误差，$e^{(2)}$表示第二个样本的误差……。</p>
<p>​    我们还可以把上面的式子写成和式的形式。使用和式，不光书写起来简单，逼格也跟着暴涨，一举两得。所以一定要写成下面这样</p>
<p>$E=e^{(1)}+e^{(2)}+e^{(3)}+\dots+e^{(n)}$ …………………(3)</p>
<p>$\sum_{i=1}^n e^{(i)} $                                             …………………(4)</p>
<p>$={1\over 2}\sum_{i=1}^n(y^(i)-\overline y^{(i)})^2$         .     …………………(5)</p>
<p>其中</p>
<p>$\overline y^{(i)}=h(x^{(i)})$  ……………………..(6)</p>
<p>$=w^Tx^{(i)}$ ………………………..(7)</p>
<p>(5)中，$x^{(i)}$表示第$i$个训练样本的特征，$y^{(i)}$表示第$i$个样本的标记，我们也可以用<strong>元组</strong>$(x^{(i)},y^{(i)})$表示第$i$个 <strong>训练样本</strong>。$\overline y^{(i)}$则是模型对第$i$个样本的<strong>预测值</strong>。</p>
<p>​    我们当然希望对于一个训练数据集来说，误差最小越好，也就是(5)的值越小越好。对于特定的训练数据集来说，$(x^{(i)},y^{(i)})$的值都是已知的，所以(式2)其实是参数$w$的函数。</p>
<p>$E(w)={1\over 2}\sum_{i=1}^n(y^{(i)}-\overline y^{(i)})^2 $               ……………………..(8)</p>
<p>$={1\over 2}\sum_{i=1}^n(y^{(i)}-w^Tx^{(i)})^2$ ………………………….(9)</p>
<p>​    由此可见，模型的训练，实际上就是求取到合适的，使(5)取得最小值。这在数学上称作<strong>优化问题</strong>，而就是我们优化的目标，称之为<strong>目标函数</strong>。</p>
<h3 id="梯度下降优化算法"><a href="#梯度下降优化算法" class="headerlink" title="梯度下降优化算法"></a>梯度下降优化算法</h3><p>​    我们学过怎样求函数的极值。函数$y=f(x)$的极值点，就是它的导数$f’(x)=0$的那个点。因此我们可以通过解方程$f’(x)=0$，求得函数的极值点$(x_0,y_0)$。</p>
<p>​    不过对于计算机来说，它可不会解方程。但是它可以凭借强大的计算能力，一步一步的去把函数的极值点『试』出来。如下图所示：</p>
<p><img src="/2018/03/31/dl1/image3.png" alt="3"></p>
<p>​    首先，我们随便选择一个点开始，比如上图的点$x_0$。接下来，每次迭代修改$x$的为，经过数次迭代后最终达到函数最小值点。</p>
<p>​    你可能要问了，为啥每次修改的值，都能往函数最小值那个方向前进呢？这里的奥秘在于，我们每次都是向函数$y=f(x)$的<strong>梯度</strong>的<strong>相反方向</strong>来修改$x$。什么是<strong>梯度</strong>呢？梯度<strong>是一个向量，它指向</strong>函数值<strong>上升最快</strong>的方向。显然，梯度的反方向当然就是函数值下降最快的方向了。我们每次沿着梯度相反方向去修改的值，当然就能走到函数的最小值附近。之所以是最小值附近而不是最小值那个点，是因为我们每次移动的步长不会那么恰到好处，有可能最后一次迭代走远了越过了最小值那个点。步长的选择是门手艺，如果选择小了，那么就会迭代很多轮才能走到最小值附近；如果选择大了，那可能就会越过最小值很远，收敛不到一个好的点上。</p>
<p>按照上面的讨论，我们就可以写出梯度下降算法的公式</p>
<p>$x_{new}=x_{old}-\eta\nabla f(x)$</p>
<p>​    其中，$\nabla$是<strong>梯度算子</strong>，$\nabla f(x)$就是指的梯度。$\eta$是步长，也称作<strong>学习速率</strong>。</p>
<p>​    对于上一节列出的目标函数(式5)</p>
<p>$E(w)={1\over2}\sum_{i=1}^n(y^{(i)}-\overline y^{(i)}$</p>
<p>梯度下降算法可以写成</p>
<p>$w_{new}=w_{old}+\eta\nabla E(w)$</p>
<p>我们要来求取$\nabla E(w)$，然后带入上式，就能得到线性单元的参数修改规则。</p>
<p>关于$\nabla E(w)$的推导过程，我单独把它们放到一节中。您既可以选择慢慢看，也可以选择无视。在这里，您只需要知道，经过一大串推导，目标函数$E(w)$的梯度是</p>
<p>$\nabla E(w)=-\sum_{i=1}^{n}(y^{(i)}-\overline y^{(i)})x^{(i)}$</p>
<p>因此，线性单元的参数修改规则最后是这个样子</p>
<p>$w_{new}=w_{old}+\eta\sum_{i=1}^n(y^{(i)}-\overline y^{(i)})$</p>
<p>有了上面这个式子，我们就可以根据它来写出训练线性单元的代码了。</p>
<p>需要说明的是，如果每个样本有M个特征，则上式w，x都是M+1维向量（因为我们加上了一个恒为1的虚拟特征$x_0$,参考前面的内容），而$y$是标量。用高逼格的数学符号表示 ，就是</p>
<p>$w,x\in R^{(M+1)}$</p>
<p>$y\in R^1$</p>
<p>为了让您看明白说的是啥，我吐血写下下面这个解释(写这种公式可累可累了)。因为$w,x$是M+1维<strong>列向量</strong>，所以(式3)可以写成<br>$$<br>\begin{bmatrix}<br>w_0 \\<br>w_1\\<br>w_2\\<br>\dots\\<br>w_m\\<br>\end{bmatrix}=\begin{bmatrix}<br>w_0 \\<br>w_1\\<br>w_2\\<br>\dots\\<br>w_m\\<br>\end{bmatrix}+\eta\sum_{i=1}^n(y^{(i)}-\overline y^{(i)})\begin{bmatrix}<br>1 \\<br>x_1^{(i)}\\<br>x_2^{(i)}\\<br>\dots\\<br>x_m^{(i)}\\<br>\end{bmatrix}<br>$$</p>
<h4 id="nabla-E-w-的推导"><a href="#nabla-E-w-的推导" class="headerlink" title="$\nabla E(w)$的推导"></a>$\nabla E(w)$的推导</h4><p>​    这一节你尽可以跳过它，并不太会影响到全文的理解。当然如果你非要弄明白每个细节，那恭喜你骚年，机器学习的未来一定是属于你的。</p>
<p>​    首先，我们先做一个简单的前戏。我们知道函数的梯度的定义就是它相对于各个变量的<strong>偏导数</strong>，所以我们写下下面的式子<br>$$<br>\nabla E(w)={\partial\over\partial w}E(w)                …………….(10)\\<br>={\partial\over \partial w}{1\over2}\sum_{i=1}^n(y^{(i)} - \overline y^{(i)})………….(11)<br>$$<br>​    可接下来怎么办呢？我们知道和的导数等于导数的和，所以我们可以先把求和符号$\sum$里面的导数求出来，然后再把它们加在一起就行了，也就是<br>$$<br>{\partial \over \partial w  }{1\over 2}\sum_{i=1}^n(y^{(i)}-\overline y^{(i)})^2…………(12)\\<br>={1\over 2}\sum_{i=1}^n{\partial\over \partial w}(y^{(i)}-\overline y^{(i)})^2…………(13)<br>$$</p>
<p>​    现在我们可以不管高大上的$\sum$了，先专心把里面的导数求出来。<br>$$<br>{\partial \over \partial w}(y^{(i)}-\overline y^{(i)})^2………………….(14)\\<br>={\partial \over \partial w}({y^{(i)}}^2-2\overline y^{(i)} +{\overline y^{(i)}}^2)………………….(15)<br>$$<br>​    我们知道，$y$是与$w$无关的常数，而$\overline y=w^Tx$,下面我们根据链式求导法则来求导。<br>$$<br>{\partial E(w)\over \partial w}={\partial E(\overline y)\over \partial\overline y}{\partial\overline y\over \partial w}<br>$$</p>
<p>我们分别计算上式等号右边的两个偏导数<br>$$<br>{\partial E(w)\over \partial \overline y}={\partial \over\partial \overline y}({y^{(i)}}^2-2\overline y^{(i)}y^{(i)}+{\overline y^{(i)}}^2)…………(16)\\<br>=-2y^{(i)}+2\overline y ^{(i)}……………….(17)<br>$$</p>
<p>$$<br>{\partial \overline y \over \partial w}={\partial \over\partial w}w^Tx ……………………..(18)\\<br>=x……………………(19)<br>$$<br>代入，我们求得$\sum$里面的偏导数是<br>$$<br>{\partial \over \partial w}(y^{(i)}-\overline y^{(i)})^2………………………..(20)\\<br>=2(-y^{(i)}+\overline y^{(i)})x……………………….(21)<br>$$<br>最后代入$\nabla E(w)$,求得<br>$$<br>\nabla E(w)={1\over2}\sum_{i=1}^n{\partial\over \partial w}(y^{(i)}-\overline y^{(i)})^2…………..(22)\\<br>={1\over 2}\sum_{i=1}^n2(-y^{(i)}+\overline y^{(i)})x…………….(23)\\<br>=-\sum_{i=1}^n(y^{(i)}-\overline y^{(i)})x……………….(25)<br>$$</p>
<h3 id="随机梯度下降算法-Stochastic-Gradient-Descent-SGD"><a href="#随机梯度下降算法-Stochastic-Gradient-Descent-SGD" class="headerlink" title="随机梯度下降算法(Stochastic Gradient Descent, SGD)"></a>随机梯度下降算法(Stochastic Gradient Descent, SGD)</h3><p>​    如果我们根据上面式子来训练模型，那么我们每次更新的迭代，要遍历训练数据中<strong>所有的样本</strong>进行计算，我们称这种算法叫做<strong>批梯度下降(Batch Gradient Descent)</strong>。如果我们的样本非常大，比如数百万到数亿，那么计算量异常巨大。因此，实用的算法是SGD算法。在SGD算法中，每次更新的迭代，只计算一个样本。这样对于一个具有数百万样本的训练数据，完成一次遍历就会对更新数百万次，效率大大提升。由于样本的噪音和随机性，每次更新并不一定按照减少的方向。然而，虽然存在一定随机性，大量的更新总体上沿着减少的方向前进的，因此最后也能收敛到最小值附近。下图展示了SGD和BGD的区别</p>
<p><img src="/2018/03/31/dl1/image4.png" alt="4"></p>
<p>​    如上图，椭圆表示的是函数值的等高线，椭圆中心是函数的最小值点。红色是BGD的逼近曲线，而紫色是SGD的逼近曲线。我们可以看到BGD是一直向着最低点前进的，而SGD明显躁动了许多，但总体上仍然是向最低点逼近的。</p>
<p>​    最后需要说明的是，SGD不仅仅效率高，而且随机性有时候反而是好事。今天的目标函数是一个『凸函数』，沿着梯度反方向就能找到全局唯一的最小值。然而对于非凸函数来说，存在许多局部最小值。随机性有助于我们逃离某些很糟糕的局部最小值，从而获得一个更好的模型。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>事实上，一个机器学习算法其实只有两部分</p>
<ul>
<li><p><strong>模型</strong> 从输入特征预测输入的那个函数</p>
</li>
<li><p><strong>目标函数</strong> 目标函数取最小(最大)值时所对应的参数值，就是模型的参数的<strong>最优值</strong>。很多时候我们只能获得目标函数的<strong>局部最小(最大)值</strong>，因此也只能得到模型参数的<strong>局部最优值</strong>。</p>
<p>因此，如果你想最简洁的介绍一个算法，列出这两个函数就行了。</p>
<p>接下来，你会用<strong>优化算法</strong>去求取目标函数的最小(最大)值。<strong>[随机]梯度{下降|上升}</strong>算法就是一个<strong>优化算法</strong>。针对同一个<strong>目标函数</strong>，不同的<strong>优化算法</strong>会推导出不同的<strong>训练规则</strong>。我们后面还会讲其它的优化算法。</p>
<p>其实在机器学习中，算法往往并不是关键，真正的关键之处在于选取特征。选取特征需要我们人类对问题的深刻理解，经验、以及思考。而<strong>神经网络</strong>算法的一个优势，就在于它能够自动学习到应该提取什么特征，从而使算法不再那么依赖人类，而这也是神经网络之所以吸引人的一个方面。</p>
<p>现在，经过漫长的烧脑，你已经具备了学习<strong>神经网络</strong>的必备知识。下一篇文章，我们将介绍本系列文章的主角：<strong>神经网络</strong>，以及用来训练神经网络的大名鼎鼎的算法：<strong>反向传播</strong>算法。至于现在，我们应该暂时忘记一切，尽情奖励自己一下吧。</p>
</li>
</ul>

      
    </div>
    
    
    

    

	<div>
      
        
      
	</div>
	
	
	<div>
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
	</div>
	
	
	
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/12/lr/" rel="next" title="逻辑回归">
                <i class="fa fa-chevron-left"></i> 逻辑回归
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/04/02/dl2/" rel="prev" title="dl2">
                dl2 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div class="ds-thread" data-thread-key="2018/03/31/dl1/"
           data-title="dl1" data-url="https://goingcoder.github.io/2018/03/31/dl1/">
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://avatars1.githubusercontent.com/u/23649220?s=400&u=964c794854ddfd2a46f55952deb5f1010bbd2982&v=4"
                alt="goingcoder" />
            
              <p class="site-author-name" itemprop="name">goingcoder</p>
              <p class="site-description motion-element" itemprop="description">匆忙世间的闲人。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/goingcoder" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            
          </div>

          
          
            <div class="cc-license motion-element" itemprop="license">
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
                <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
              </a>
            </div>
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.hustyrf.top" title="陈冠希" target="_blank">陈冠希</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性单元"><span class="nav-number">1.</span> <span class="nav-text"><a href="#&#x7EBF;&#x6027;&#x5355;&#x5143;" class="headerlink" title="&#x7EBF;&#x6027;&#x5355;&#x5143;"></a>&#x7EBF;&#x6027;&#x5355;&#x5143;</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线性单元的模型"><span class="nav-number">1.1.</span> <span class="nav-text"><a href="#&#x7EBF;&#x6027;&#x5355;&#x5143;&#x7684;&#x6A21;&#x578B;" class="headerlink" title="&#x7EBF;&#x6027;&#x5355;&#x5143;&#x7684;&#x6A21;&#x578B;"></a>&#x7EBF;&#x6027;&#x5355;&#x5143;&#x7684;&#x6A21;&#x578B;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#监督学习和无监督学习"><span class="nav-number">1.2.</span> <span class="nav-text"><a href="#&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x548C;&#x65E0;&#x76D1;&#x7763;&#x5B66;&#x4E60;" class="headerlink" title="&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x548C;&#x65E0;&#x76D1;&#x7763;&#x5B66;&#x4E60;"></a>&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x548C;&#x65E0;&#x76D1;&#x7763;&#x5B66;&#x4E60;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性单元的目标函数"><span class="nav-number">1.3.</span> <span class="nav-text"><a href="#&#x7EBF;&#x6027;&#x5355;&#x5143;&#x7684;&#x76EE;&#x6807;&#x51FD;&#x6570;" class="headerlink" title="&#x7EBF;&#x6027;&#x5355;&#x5143;&#x7684;&#x76EE;&#x6807;&#x51FD;&#x6570;"></a>&#x7EBF;&#x6027;&#x5355;&#x5143;&#x7684;&#x76EE;&#x6807;&#x51FD;&#x6570;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度下降优化算法"><span class="nav-number">1.4.</span> <span class="nav-text"><a href="#&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x4F18;&#x5316;&#x7B97;&#x6CD5;" class="headerlink" title="&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x4F18;&#x5316;&#x7B97;&#x6CD5;"></a>&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x4F18;&#x5316;&#x7B97;&#x6CD5;</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#nabla-E-w-的推导"><span class="nav-number">1.4.1.</span> <span class="nav-text"><a href="#nabla-E-w-&#x7684;&#x63A8;&#x5BFC;" class="headerlink" title="$\nabla E(w)$&#x7684;&#x63A8;&#x5BFC;"></a>$\nabla E(w)$&#x7684;&#x63A8;&#x5BFC;</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机梯度下降算法-Stochastic-Gradient-Descent-SGD"><span class="nav-number">1.5.</span> <span class="nav-text"><a href="#&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;-Stochastic-Gradient-Descent-SGD" class="headerlink" title="&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;(Stochastic Gradient Descent, SGD)"></a>&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;(Stochastic Gradient Descent, SGD)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#小结"><span class="nav-number">2.</span> <span class="nav-text"><a href="#&#x5C0F;&#x7ED3;" class="headerlink" title="&#x5C0F;&#x7ED3;"></a>&#x5C0F;&#x7ED3;</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">goingcoder</span>

  
</div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.3</div>

-->



        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"your-duoshuo-shortname"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  


















  





  

  

  

  
  

  
  


  

  

</body>
</html>
